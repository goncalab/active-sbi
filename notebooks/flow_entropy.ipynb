{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th \n",
    "from copy import deepcopy \n",
    "from sbi.inference import NLE \n",
    "from asbi.tasks import get_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = get_task(\"two_moons\")\n",
    "prior = task.get_prior_dist()\n",
    "simulator = task.get_simulator()\n",
    "\n",
    "n_sims = 1000\n",
    "n_ensemble_members = 3\n",
    "\n",
    "ensemble = [NLE(prior, density_estimator='maf') for _ in range(n_ensemble_members)]\n",
    "theta = prior((n_sims,))\n",
    "x = simulator(theta)\n",
    "\n",
    "for inference in ensemble:\n",
    "    _ = inference.append_simulations(theta, x).train()\n",
    "    print(' training done')\n",
    "\n",
    "flows = [deepcopy(inference._neural_net) for inference in ensemble]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from asbi.algorithms.EnsembleFlow import EnsembleFlow\n",
    "ensemble_flow = EnsembleFlow(flows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior((1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = prior((1,))[0]\n",
    "\n",
    "samples = ensemble_flow.sample(33, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs = ensemble_flow.log_prob(samples, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Remove outliers below -10\n",
    "filtered_log_probs = np.exp(log_probs[log_probs > -10])\n",
    "\n",
    "plt.figure(figsize=(10, 6), dpi=400)\n",
    "plt.hist(filtered_log_probs.numpy(), bins=30)\n",
    "plt.xlabel('Log Probability')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Log Probabilities')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Remove outliers below -10\n",
    "filtered_log_probs = np.exp(log_probs[log_probs > -10])\n",
    "\n",
    "plt.hist(filtered_log_probs.numpy(), bins=30)\n",
    "plt.xlabel('Log Probability')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Log Probabilities')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_flow.compute_marginal_entropy(t, N=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = prior((1,))\n",
    "\n",
    "\n",
    "samples = []\n",
    "for flow in flows:\n",
    "    s = flow.sample((10,), theta)\n",
    "    samples.append(s)\n",
    "\n",
    "th.cat(samples, dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleFlow:\n",
    "    def __init__(self, flows) -> None:\n",
    "        self.n_flows = len(flows)\n",
    "        self.flows = flows\n",
    "\n",
    "    def log_prob(self, x, condition):\n",
    "        with th.no_grad():\n",
    "            log_probs = [flow.log_prob(x, condition) for flow in self.flows]\n",
    "            stacked = th.stack(log_probs, dim=0).mean(dim=0)\n",
    "            return stacked\n",
    "\n",
    "    def sample(self, n_samples, condition):\n",
    "        # generate samples from mixture of flows\n",
    "        n = n_samples // self.n_flows        \n",
    "        samples = []\n",
    "        for flow in self.flows:\n",
    "            samples.append(flow.sample((n,), condition))\n",
    "\n",
    "        if n_samples % self.n_flows != 0:\n",
    "            samples.append(flow.sample((int(n_samples % self.n_flows),), condition))\n",
    "        \n",
    "        return th.cat(samples, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_flow = EnsembleFlow(flows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = ensemble_flow.sample(103, theta)\n",
    "\n",
    "ensemble_flow.log_prob(samples, theta).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "flow = deepcopy(inference._neural_net)\n",
    "\n",
    "flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = flow.sample((10,), theta.unsqueeze(0))\n",
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = flow.sample((2, 3), theta.unsqueeze(0))\n",
    "\n",
    "samples.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th \n",
    "\n",
    "theta = prior.sample()\n",
    "with th.no_grad():  \n",
    "    samples = flow.sample((1000,), theta.unsqueeze(0))\n",
    "    log_prob = - th.mean(flow.log_prob(samples, theta.unsqueeze(0)))\n",
    "\n",
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow.log_prob(samples, theta.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference._density_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
